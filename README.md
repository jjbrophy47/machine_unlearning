 # Machine Unlearning Papers and Benchmarks
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
![Github repo stars](https://img.shields.io/github/stars/jjbrophy47/machine_unlearning)
![GitHub last commit](https://img.shields.io/github/last-commit/jjbrophy47/machine_unlearning)


## Benchmarks

[OpenUnlearning](https://github.com/locuslab/open-unlearning)

[Machine Unlearning Comparator](https://github.com/gnueaj/Machine-Unlearning-Comparator)

## Papers

[2025](#2025) &nbsp;
[2024](#2024) &nbsp;
[2023](#2023) &nbsp;
[2022](#2022) &nbsp;
[2021](#2021) &nbsp;
[2020](#2020) &nbsp;
[2019](#2019) &nbsp;
[2018](#2018) &nbsp;
[2017](#2017) &nbsp;
[< 2017](#before-2017) &nbsp;

### 2025
| Author(s)       | Title                                                                                                                         | Venue |
|:----------------|-------------------------------------------------------------------------------------------------------------------------------|-------|
| Mekala et al.   | [Alternate Preference Optimization for Unlearning Factual Knowledge in Large Language Models](https://arxiv.org/pdf/2409.13474) | COLING |
| Zhou et al.   | [Decoupled Distillation to Erase: A General Unlearning Method for Any Class-centric Tasks](https://arxiv.org/abs/2503.23751) | CVPR |
| Choi et al.     | [Unlearning-based Neural Interpretations](https://arxiv.org/pdf/2410.08069) | ICLR |
| Di et al. | [Adversarial Machine Unlearning](https://openreview.net/pdf?id=swWF948IiC) | ICLR |
| Li et al.       | [When is Task Vector Provably Effective for Model Editing? A Generalization Analysis of Nonlinear Transformers](https://openreview.net/pdf?id=vRvVVb0NAz) | ICLR |
| Scholten et al. | [A Probabilistic Perspective on Unlearning and Alignment for Large Language Models](https://arxiv.org/pdf/2410.03523) | ICLR |
| Wang et al.   | [Towards Lifecycle Unlearning Commitment Management: Measuring Sample-level Unlearning Completeness](https://arxiv.org/abs/2506.06112) | USENIX Security |
| Wang et al. | [TAPE: Tailored Posterior Difference for Auditing of Machine Unlearning](https://openreview.net/forum?id=LedrHK34jZ#discussion) | WWW |
| | |
| Vidal et al. | [Machine Unlearning in Hyperbolic vs. Euclidean Multimodal Contrastive Learning: Adapting Alignment Calibration to MERU](https://arxiv.org/abs/2503.15166)) | CVPR Workshop |
| | |
| Kim et al.      | [Are We Truly Forgetting? A Critical Re-examination of Machine Unlearning Evaluation Protocols](https://arxiv.org/pdf/2503.06991) | arxiv |
| Kwak et al.     | [NegMerge: Consensual Weight Negation for Strong Machine Unlearning](https://arxiv.org/pdf/2410.05583) | arxiv |
| Wang et al.     | [GRU: Mitigating the Trade-off between Unlearning and Retention for Large Language Models](https://arxiv.org/pdf/2503.09117) | arxiv |


### 2024
| Author(s) | Title | Venue |
|:--------- | ----- | ----- |
| Cha et al. | [Learning to Unlearn: Instance-wise Unlearning for Pre-trained Classifiers](https://arxiv.org/abs/2301.11578) | AAAI |
| Foster et al. | [Fast Machine Unlearning Without Retraining Through Selective Synaptic Dampening](https://arxiv.org/abs/2308.07707) | AAAI |
| Hu et al. | [Separate the Wheat from the Chaff: Model Deficiency Unlearning via Parameter-Efficient Module Operation](https://arxiv.org/abs/2308.08090) | AAAI |
| Li et al. | [Towards Effective and General Graph Unlearning via Mutual Evolution](https://arxiv.org/abs/2401.11760) | AAAI |
| Liu et al. | [Backdoor Attacks via Machine Unlearning](https://ojs.aaai.org/index.php/AAAI/article/view/29321) | AAAI |
| You et al. | [RRL: Recommendation Reverse Learning](https://ojs.aaai.org/index.php/AAAI/article/view/28782) | AAAI |
| Lin et al. | [GDR-GMA: Machine Unlearning via Direction-Rectified and Magnitude-Adjusted Gradients](https://dl.acm.org/doi/abs/10.1145/3664647.3680775?casa_token=rSkm62J9YJAAAAAA:uBuDmmFVPV5qYz3Ydan4q99mCx-T3E6DwTOyAMtkwuMd_v_oy800AUVgGLzljbnAueX3uicgLRr_TA) | ACM MM |
| Fraboni et al. | [SIFU: Sequential Informed Federated Unlearning for Efficient and Provable Client Unlearning in Federated Optimization](https://arxiv.org/abs/2211.11656) | AISTATS |
| Alshehri and Zhang | [Forgetting User Preference in Recommendation Systems with Label-Flipping](https://ieeexplore.ieee.org/abstract/document/10386603/authors#authors) | BigData |
| Qiu et al. | [FedCIO: Efficient Exact Federated Unlearning with Clustering, Isolation, and One-shot Aggregation](https://ieeexplore.ieee.org/document/10386788) | BigData |
| Yang and Li | [When Contrastive Learning Meets Graph Unlearning: Graph Contrastive Unlearning for Link Prediction](https://ieeexplore.ieee.org/abstract/document/10386624?casa_token=Bjay4FnV6nsAAAAA:ELDmygCAnGPf0IPUL5BBApBE7oJauAxYMGUkWZlWMHIqYVGk7dksuZ_Ui-ahThfHYe3Kbgb4xw) | BigData |
| Hu et al. | [ERASER: Machine Unlearning in MLaaS via an Inference Serving-Aware Approach](https://arxiv.org/abs/2311.16136) | CCS |
| Zhang et al. | [Negative Preference Optimization: From Catastrophic Collapse to Effective Unlearning](https://arxiv.org/abs/2404.05868) | COLM |
| Abbasi et al. | [Brainwash: A Poisoning Attack to Forget in Continual Learning](https://arxiv.org/abs/2311.11995) | CVPR |
| Fan et al. | [Challenging Forgets: Unveiling the Worst-Case Forget Sets in Machine Unlearning](https://arxiv.org/abs/2403.07362)| ECCV |
| Wu et al. | [Scissorhands: Scrub Data Influence via Connection Sensitivity in Networks](https://arxiv.org/abs/2401.06187) | ECCV |
| Zhang et al. | [To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy To Generate Unsafe Images ... For Now](https://arxiv.org/abs/2310.11868) | ECCV |
| Wang et al. | [How to Forget Clients in Federated Online Learning to Rank?](https://arxiv.org/abs/2401.13410) | ECIR |
| Jia et al. | [SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning](https://arxiv.org/abs/2404.18239) | EMNLP |
| Liu et al. | [Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective](https://arxiv.org/abs/2407.16997) | EMNLP |
| Fan et al. | [SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation](https://openreview.net/forum?id=gn0mIhQGNM) | ICLR |
| Liu et al. | [Tangent Transformers for Composition, Privacy and Removal](https://openreview.net/forum?id=VLFhbOCz5D) | ICLR |
| Li et al. | [Machine Unlearning for Image-to-Image Generative Models](https://openreview.net/forum?id=9hjVoPWPnh) | ICLR |
| Shen et al. | [Label-Agnostic Forgetting: A Supervision-Free Unlearning in Deep Models](https://openreview.net/forum?id=SIZWiya7FE) | ICLR |
| Tsai et al. | [Ring-A-Bell! How Reliable are Concept Removal Methods for Diffusion Models?](https://arxiv.org/abs/2310.10012) | ICLR |
| Wang et al. | [A Unified and General Framework for Continual Learning](https://openreview.net/forum?id=BE5aK0ETbp) | ICLR |
| Zhao et al. | [Rethinking Adversarial Robustness in the Context of the Right to be Forgotten](https://icml.cc/virtual/2024/poster/32857) | ICML |
| Xue et al. | [Erase to Enhance: Data-Efficient Machine Unlearning in MRI Reconstruction](https://arxiv.org/pdf/2405.15517) | MIDL |
| Bui et al. | [Erasing Undesirable Concepts in Diffusion Models with Adversarial Preservation](https://arxiv.org/abs/2410.15618) | NeurIPS |
| Ji et al. | [Reversing the Forget-Retain Objectives: An Efficient LLM Unlearning Framework from Logit Difference](https://arxiv.org/abs/2406.08607) | NeurIPS |
| Zhao et al. | [What makes unlearning hard and what to do about it](https://arxiv.org/abs/2406.01257) | NeurIPS |
| Zhang et al. | [Defensive Unlearning with Adversarial Training for Robust Concept Erasure in Diffusion Models](https://arxiv.org/abs/2405.15234) | NeurIPS |
| Zhang et al. | [UnlearnCanvas: A Stylized Image Dataset to Benchmark Machine Unlearning for Diffusion Models](https://arxiv.org/abs/2402.11846) | NeurIPS D&B |
| Kurmanji et al. | [Machine Unlearning in Learned Databases: An Experimental Analysis](https://arxiv.org/abs/2311.17276) | SIGMOD |
| Shen et al. | [CaMU: Disentangling Causal Effects in Deep Model Unlearning](https://epubs.siam.org/doi/abs/10.1137/1.9781611978032.89) | SDM |
| Hoang et al. | [Learn To Unlearn for Deep Neural Networks: Minimizing Unlearning Interference With Gradient Projection](https://openaccess.thecvf.com/content/WACV2024/html/Hoang_Learn_To_Unlearn_for_Deep_Neural_Networks_Minimizing_Unlearning_Interference_WACV_2024_paper.html) | WACV |
| Xin et al. | [On the Effectiveness of Unlearning in Session-Based Recommendation](https://dl.acm.org/doi/abs/10.1145/3616855.3635823) | WSDM |
| Zhang | [Graph Unlearning with Efficient Partial Retraining](https://dl.acm.org/doi/abs/10.1145/3589335.3651265) | WWW |
| | |
| Li et al. | [Pseudo Unlearning via Sample Swapping with Hash](https://www.sciencedirect.com/science/article/abs/pii/S0020025524000483?via%3Dihub) | Information Science |
| | |
| Zhao et al. | [Scalability of memorization-based machine unlearning](https://arxiv.org/abs/2410.16516) | NeurIPS Workshop|
| | |
| Dontsov et al. | [CLEAR: Character Unlearning in Textual and Visual Modalities](https://arxiv.org/abs/2410.18057) | arXiv |
| Fan et al. | [Simplicity Prevails: Rethinking Negative Preference Optimization for LLM Unlearning](https://arxiv.org/abs/2410.07163) | arXiv |
| Foster et al. | [Zero-Shot Machine Unlearning at Scale via Lipschitz Regularization](https://arxiv.org/abs/2402.01401) | arXiv |
| Hong et al. | [Intrinsic Evaluation of Unlearning Using Parametric Knowledge Traces]( https://arxiv.org/pdf/2406.11614) | arXiv |
| Maini et al. | [TOFU: A Task of Fictitious Unlearning for LLMs](https://arxiv.org/abs/2401.06121) | arXiv |
| Jung et al. | [Attack and Reset for Unlearning: Exploiting Adversarial Noise toward Machine Unlearning through Parameter Re-initialization](https://arxiv.org/abs/2401.08998) | arXiv |
| Liu et al. | [Rethinking Machine Unlearning for Large Language Models](https://arxiv.org/abs/2402.08787) | arXiv |
| Lucki et al. | [An Adversarial Perspective on Machine Unlearning for AI Safety](https://arxiv.org/abs/2409.18025) | arXiv |
| Pham et al. | [Robust Concept Erasure Using Task Vectors](https://arxiv.org/abs/2404.03631) | arXiv |
| Qian et al. | [Exploring Fairness in Educational Data Mining in the Context of the Right to be Forgotten](https://arxiv.org/abs/2405.16798) | arXiv |
| Romandini et al. | [Federated Unlearning: A Survey on Methods, Design Guidelines, and Evaluation Metrics](https://arxiv.org/abs/2401.05146) | arXiv |
| Schoepf et al. | [Potion: Towards Poison Unlearning](https://arxiv.org/abs/2406.09173) | arXiv |
| Schoepf et al. | [Parameter-tuning-free data entry error unlearning with adaptive selective synaptic dampening](https://arxiv.org/abs/2402.10098) | arXiv |
| Wu et al. | [EraseDiff: Erasing Data Influence In Diffusion Models](https://arxiv.org/abs/2401.05779) | arXiv |
| Yao et al. | [Machine Unlearning of Pre-trained Large Language Models](https://arxiv.org/abs/2402.15159) | arXiv |
| Zhang et al. | [Does your LLM truly unlearn? An embarrassingly simple approach to recover unlearned knowledge](https://arxiv.org/abs/2410.16454) | arXiv |
| Zhao et al. | [Separable Multi-Concept Erasure from Diffusion Models](https://arxiv.org/abs/2402.05947) | arXiv |
| Zuo et al. | [Machine unlearning through fine-grained model parameters perturbation](https://arxiv.org/abs/2401.04385) | arXiv |

### 2023
| Author(s) | Title | Venue |
|:--------- | ----- | ----- |
| Wang et al. | [KGA: A General Machine Unlearning Framework Based on Knowledge Gap Alignment](https://arxiv.org/abs/2305.06535) | ACL |
| Yu et al. | [Unlearning Bias in Language Models by Partitioning Gradients](https://aclanthology.org/2023.findings-acl.375.pdf) | ACL |
| Zhang et al. | [Machine Unlearning Methodology base on Stochastic Teacher Network](https://arxiv.org/abs/2308.14322) | ADMA |
| Ye and Lu | [Sequence Unlearning for Sequential Recommender Systems](https://link.springer.com/chapter/10.1007/978-981-99-8388-9_33) | AI |
| Wang et al. | [BFU: Bayesian Federated Unlearning with Parameter Self-Sharing](https://dl.acm.org/doi/abs/10.1145/3579856.3590327) | Asia CCS |
| Lee and Woo | [UNDO: Effective and Accurate Unlearning Method for Deep Neural Networks](https://dl.acm.org/doi/abs/10.1145/3583780.3615235?casa_token=-nyxssmE9b0AAAAA:dpYILftUNiAz5Bh7hrr95SNjYKj61yVYb3kIIv8v5rXDyKNdn1xWYdovqkYrQG9AxbL6P-eah9En) | CIKM |
| Ghazi et al. | [Ticketed Learning-Unlearning Schemes](https://arxiv.org/abs/2306.15744) | COLT |
| Chen et al. | [Boundary Unlearning: Rapid Forgetting of Deep Networks via Shifting the Decision Boundary](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Boundary_Unlearning_Rapid_Forgetting_of_Deep_Networks_via_Shifting_the_CVPR_2023_paper.html) | CVPR |
| Lin et al. | [ERM-KTP: Knowledge-Level Machine Unlearning via Knowledge Transfer](https://openaccess.thecvf.com/content/CVPR2023/html/Lin_ERM-KTP_Knowledge-Level_Machine_Unlearning_via_Knowledge_Transfer_CVPR_2023_paper.html) | CVPR |
| Hagos et al. | [Unlearning Spurious Correlations in Chest X-ray Classification](https://arxiv.org/abs/2308.01119) | Discovery Science |
| Mireshghallah et al. | [Simple Temporal Adaptation to Changing Label Sets: Hashtag Prediction via Dense KNN](https://aclanthology.org/2023.emnlp-main.452/) | EMNLP |
| Gandikota et al. | [Erasing Concepts from Diffusion Models](https://openaccess.thecvf.com/content/ICCV2023/papers/Gandikota_Erasing_Concepts_from_Diffusion_Models_ICCV_2023_paper.pdf) | ICCV |
| Kumari et al. | [Ablating Concepts in Text-to-Image Diffusion Models](https://github.com/nupurkmr9/concept-ablation) | ICCV |
| Liu et al. | [MUter: Machine Unlearning on Adversarially Trained Models](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_MUter_Machine_Unlearning_on_Adversarially_Trained_Models_ICCV_2023_paper.html) | ICCV |
| Zheng et al. | [Graph Unlearning Using Knowledge Distillation](https://link.springer.com/chapter/10.1007/978-981-99-7356-9_29) | ICICS |
| Cheng et al. | [GNNDelete: A General Strategy for Unlearning in Graph Neural Networks](https://arxiv.org/abs/2302.13406) | ICLR |
| Chien et al. | [Efficient Model Updates for Approximate Unlearning of Graph-Structured Data](https://openreview.net/forum?id=fhcu4FBLciL) | ICLR |
| Che et al. | [Fast Federated Machine Unlearning with Nonlinear Functional Theory](https://openreview.net/forum?id=6wQKmKiDHw) | ICML |
| Liu et al. | [Machine Unlearning with Affine Hyperplane Shifting and Maintaining for Image Classification](https://link.springer.com/chapter/10.1007/978-981-99-8178-6_17) | ICONIP |
| Lin et al. | [Machine Unlearning in Gradient Boosting Decision Trees](https://dl.acm.org/doi/10.1145/3580305.3599420) | KDD |
| Qian et al. | [Towards Understanding and Enhancing Robustness of Deep Learning Models against Malicious Unlearning Attacks](https://dl.acm.org/doi/abs/10.1145/3580305.3599526) | KDD |
| Wu et al. | [Certified Edge Unlearning for Graph Neural Networks](https://yue-ning.github.io/docs/kdd23-ceu.pdf) | KDD |
| Li et al. | [Making Users Indistinguishable: Attribute-wise Unlearning in Recommender Systems](https://dl.acm.org/doi/abs/10.1145/3581783.3612418) | MM |
| Hu et al. | [A Duty to Forget, a Right to be Assured? Exposing Vulnerabilities in Machine Unlearning Services](https://arxiv.org/abs/2309.08230) | NDSS |
| Warnecke et al. | [Machine Unlearning for Features and Labels](https://arxiv.org/abs/2108.11577) | NDSS |
| Chen et al. | [Fast Model Debias with Machine Unlearning](https://arxiv.org/abs/2310.12560) | NeurIPS |
| Kurmanji et al. | [Towards Unbounded Machine Unlearning](https://arxiv.org/abs/2302.09880) | NeurIPS |
| Li et al. | [UltraRE: Enhancing RecEraser for Recommendation Unlearning via Error Decomposition](https://neurips.cc/virtual/2023/poster/72617) | NeurIPS |
| Liu et al. | [Certified Minimax Unlearning with Generalization Rates and Deletion Capacity](https://neurips.cc/virtual/2023/poster/72765) | NeurIPS |
| Jia et al. | [Model Sparsification Can Simplify Machine Unlearning](https://arxiv.org/abs/2304.04934) | NeurIPS |
| Wei et al. | [Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples](https://neurips.cc/virtual/2023/poster/69874) | NeurIPS |
| Di et al. | [Hidden Poison: Machine Unlearning Enables Camouflaged Poisoning Attacks](https://neurips.cc/virtual/2023/poster/72092) | NeurIPS |
| Heng et al. | [Selective Amnesia: A Continual Learning Approach to Forgetting in Deep Generative Models](https://arxiv.org/abs/2305.10120) | NeurIPS |
| Zhao et al. | [Static and Sequential Malicious Attacks in the Context of Selective Forgetting](https://proceedings.neurips.cc/paper_files/paper/2023/hash/ed4bacc8c7ca1ee0e1d4e0ef376b7ac7-Abstract-Conference.html) | NeurIPS |
| Leysen | [Exploring Unlearning Methods to Ensure the Privacy, Security, and Usability of Recommender Systems](https://dl.acm.org/doi/abs/10.1145/3604915.3608862?casa_token=gf7H1bpjdYoAAAAA:133RDRcYB5BKrUgtIDHKzddEMIwqcPKbr22LILZNBNmzshoWrEy1JAWbNqb6-iKRWtxX0rtVM2K3) | RecSys |
| Koch and Soll | [No Matter How You Slice It: Machine Unlearning with SISA Comes at the Expense of Minority Classes](https://openreview.net/forum?id=RBX1H-SGdT) | SaTML |
| Schelter et al. | [Forget Me Now: Fast and Exact Unlearning in Neighborhood-based Recommendation](https://ssc.io/pdf/caboose.pdf) | SIGIR |
| Kurmanji et al. | [Machine Unlearning in Learned Databases: An Experimental Analysis](https://arxiv.org/abs/2311.17276) | SIGMOD |
| Wu et al. | [DeltaBoost: Gradient Boosting Decision Trees with Efficient Machine Unlearning](https://dl.acm.org/doi/abs/10.1145/3589313) | SIGMOD |
| Wang et al. | [Inductive Graph Unlearning](https://arxiv.org/abs/2304.03093) | USENIX Security |
| Xia et al. | [Equitable Data Valuation Meets the Right to Be Forgotten in Model Markets](https://www.vldb.org/pvldb/vol16/p3349-liu.pdf) | VLDB |
| Sun et al. | [Lazy Machine Unlearning Strategy for Random Forests](https://link.springer.com/chapter/10.1007/978-981-99-6222-8_32) | WISA |
| Pan et al. | [Unlearning Graph Classifiers with Limited Data Resources](https://dl.acm.org/doi/10.1145/3543507.3583547) | WWW |
| Wu et al. | [GIF: A General Graph Unlearning Strategy via Influence Function](https://dl.acm.org/doi/abs/10.1145/3543507.3583521) | WWW |
| Zhu et al. | [Heterogeneous Federated Knowledge Graph Embedding Learning and Unlearning](https://arxiv.org/abs/2302.02069) | WWW |
| | |
| Chen et al. | [Privacy preserving machine unlearning for smart cities](https://link.springer.com/article/10.1007/s12243-023-00960-z) | Annals of Telemcommunications |
| Zhang et al. | [Machine Unlearning by Reversing the Continual Learning](https://www.mdpi.com/2076-3417/13/16/9341) | Applied Sciences |
| Sai et al. | [Machine Un-learning: An Overview of Techniques, Applications, and Future Directions](https://link.springer.com/article/10.1007/s12559-023-10219-3) | Cognitive Computation |
| Tang et al. | [Ensuring User Privacy and Model Security via Machine Unlearning: A Review](https://cdn.techscience.cn/files/cmc/2023/TSP_CMC-77-2/TSP_CMC_32307/TSP_CMC_32307.pdf) | Computers, Materials, and Continua |
| Deng et al. | [Vertical Federated Unlearning on the Logistic Regression Model](https://www.mdpi.com/2079-9292/12/14/3182) | Electronics |
| Zeng at al. | [Towards Highly-efficient and Accurate Services QoS Prediction via Machine Unlearning](https://ieeexplore.ieee.org/abstract/document/10171348) | IEEE Access |
| Zhao et al. | [Federated Unlearning With Momentum Degradation](https://ieeexplore.ieee.org/abstract/document/10269017?casa_token=Lk5378AkwaoAAAAA:i_KUf5hO1pdYtnnOxkX6SUO-QvICIs48m2RNK45hz6vkcF8FHY9R5jIF56pcnFdXkZJzrSax1w) | IEEE IOT Journal |
| Xia et al. | [FedME2: Memory Evaluation & Erase Promoting Federated Unlearning in DTMN](https://ieeexplore.ieee.org/abstract/document/10234397?casa_token=B7ZLOqWtAsEAAAAA:rv_j5JuHFyFgKw3v7f7-aRPyhWQZFfHD_IxC84xObXsB54wn30_Cy1l7t72qG2ubfrQtkWKutw) | IEEE Selected Areas in Communications |
| Zhang et al. | [Poison Neural Network-Based mmWave Beam Selection and Detoxification With Machine Unlearning](https://ieeexplore.ieee.org/abstract/document/10002349?casa_token=ZxD2jHH8zJsAAAAA:_tuHzhnRtrBXqhy4YBHFfHQfYe-8Lex2RqXXCQN2KYGGq5G8vo9m279GRvcVVPWT1h3w-vd-Ug) | IEEE Trans. on Comm. |
| Chundawat et al. | [Zero-Shot Machine Unlearning](https://ieeexplore.ieee.org/abstract/document/10097553?casa_token=lJiaqTXbuSgAAAAA:aCe66PZHwYXjfAoLNp5qFQ43ArbBx_SyPjWZ4QII2uWuNJlgt7lM-VK6yszcfrAiY1iRumdu_w) | IEEE Trans. Info. Forensics and Security |
| Wang et al. | [Machine Unlearning via Representation Forgetting with Parameter Self-Sharing](https://ieeexplore.ieee.org/abstract/document/10312776?casa_token=fECifyR2hr0AAAAA:TOGn5ijpteiECxqvsonf-qzKjS_tnH2hGUP3xvLIScpD0EWTjEQPt4qjuLymDD6EyyL_Lkw) | IEEE Trans. Info. Forensics and Security |
| Guo et al. | [Verifying in the Dark: Verifiable Machine Unlearning by Using Invisible Backdoor Triggers](https://ieeexplore.ieee.org/abstract/document/10298847?casa_token=Otcu10L0CYgAAAAA:p5k-Vtb-CNJdl4hmcCfO0bMLUcpA4erakCBhp6ESuEekfsh7pFlXTZ3p_VLjg0T68npCo0D7pg) | IEEE Trans. Info. Forensics and Security | 
| Zhang et al. | [FedRecovery: Differentially Private Machine Unlearning for Federated Learning Frameworks](https://ieeexplore.ieee.org/abstract/document/10189868?casa_token=LSZ_zxmfBdsAAAAA:WsKW6DHd4ZaVEM04VkpggSP7C7-pWyN9j-8nqWA_0vG35DjVgJHcC9CfIz8d694JXssrJJk1) | IEEE Trans. Info. Forensics and Security |
| Guo et al. | [FAST: Adopting Federated Unlearning to Eliminating Malicious Terminals at Server Side](https://ieeexplore.ieee.org/abstract/document/10360312?casa_token=FD0AYUAaQ8sAAAAA:xDqcan2H3_-KEbiSA1DtDL7kVSHTI-hMA6srzpvsKniHKWDLvF-oHZ1latt0LUK7UgsdZCshDA) | IEEE Trans. Network Science and Engineering |
| Tarun et al. | [Fast Yet Effective Machine Unlearning](https://ieeexplore.ieee.org/abstract/document/10113700?casa_token=7dFrOAGnBGQAAAAA:6itSHHPr3BdQ8jk3-KaeyujIDB3Xs5ADE38dSOZFuDvFj8NpSrmmi0vnsfIcTJ74HAAh--D_Mg) | IEEE Trans. Neural Net. and Learn. Systems |
| Tang et al. | [Fuzzy rough unlearning model for feature selection](https://www.sciencedirect.com/science/article/abs/pii/S0888613X23002335) | International Journal of Approximate Reasoning |
| Zhu et al. | [Hierarchical Machine Unlearning](https://books.google.com/books?hl=en&lr=&id=uQjfEAAAQBAJ&oi=fnd&pg=PA92&ots=Yj2HPJ_NzO&sig=-NWR1JKVzMA3ftTWADuUGyg2Wlc#v=onepage&q&f=false) | Learning and Intelligent Optimization |
| Floridi | [Machine Unlearning: its nature, scope, and importance for a “delete culture”](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4455976) | Philosophy & Technology |
| Zhang et al. | [A Review on Machine Unlearning](https://link.springer.com/article/10.1007/s42979-023-01767-4) | SN Computer Science |
| | |
| Oesterling et al. | [Fair Machine Unlearning: Data Removal while Mitigating Disparities](https://arxiv.org/abs/2307.14754) | DMLR Workshop |
| Llamas et al. | [Effective Machine Learning-based Access Control Administration through Unlearning](https://ieeexplore.ieee.org/abstract/document/10190682?casa_token=ejAyrscJ-vwAAAAA:o0Ud_9o0VDeiHsjUoteVzt1AbOaAUgN6AKepATztFdfSfWMgKugrNG7sLP9Hcyia013w72Mj) | EuroS&PW |
| Bae et al. | [Gradient Surgery for One-shot Unlearning on Generative Model](https://arxiv.org/abs/2307.04550) | Generative AI & LAW Workshop |
| | |
| Abbasi et al. | [CovarNav: Machine Unlearning via Model Inversion and Covariance Navigation](https://arxiv.org/abs/2311.12999) | arXiv |
| Alam et al. | [Get Rid Of Your Trail: Remotely Erasing Backdoors in Federated Learning](https://arxiv.org/abs/2304.10638) | arXiv |
| Bother et al. | [Modyn: A Platform for Model Training on Dynamic Datasets With Sample-Level Data Selection](https://arxiv.org/abs/2312.06254) | arXiv |
| Cai et al. | [Where have you been? A Study of Privacy Risk for Point-of-Interest Recommendation](https://arxiv.org/abs/2310.18606) | arXiv |
| Cha et al. | [Learning to Unlearn: Instance-wise Unlearning for Pre-trained Classifiers](https://arxiv.org/abs/2301.11578) | arXiv |
| Chen et al. | [Unlearn What You Want to Forget: Efficient Unlearning for LLMs](https://arxiv.org/abs/2310.20150) | arXiv |
| Cheng et al. | [Multimodal Machine Unlearning](https://arxiv.org/abs/2311.12047) | arXiv |
| Cong and Mahdavi | [Efficiently Forgetting What You Have Learned in Graph Representation Learning via Projection](https://arxiv.org/abs/2302.08990) | arXiv |
| Cotogni et al. | [DUCK: Distance-based Unlearning via Centroid Kinematics](https://arxiv.org/abs/2312.02052) | arXiv |
| Dam et al. | [Delete My Account: Impact of Data Deletion on Machine Learning Classifiers](https://arxiv.org/abs/2311.10385) | arXiv |
| Dhasade et al. | [QuickDrop: Efficient Federated Unlearning by Integrated Dataset Distillation](https://arxiv.org/abs/2311.15603) | arXiv |
| Dukler et al. | [SAFE: Machine Unlearning With Shard Graphs](https://arxiv.org/abs/2304.13169) | arXiv |
| Eldan et al. | [Who’s Harry Potter? Approximate Unlearning in LLMs](https://arxiv.org/abs/2310.02238) | arXiv |
| Foster et al. | [Fast Machine Unlearning Without Retraining Through Selective Synaptic Dampening](https://arxiv.org/abs/2308.07707) | arXiv |
| Hong et al. | [All but One: Surgical Concept Erasing with Model Preservation in Text-to-Image Diffusion Models](https://arxiv.org/abs/2312.12807) | arXiv |
| Huang et al. | [Tight Bounds for Machine Unlearning via Differential Privacy](https://arxiv.org/abs/2309.00886) | arXiv |
| Huang et al. | [Receler: Reliable Concept Erasing of Text-to-Image Diffusion Models via Lightweight Erasers](https://arxiv.org/abs/2311.17717) | arXiv |
| Jin et al. | [Forgettable Federated Linear Learning with Certified Data Removal](https://arxiv.org/abs/2306.02216) | arXiv |
| Kim et al. | [Layer Attack Unlearning: Fast and Accurate Machine Unlearning via Layer Level Attack and Knowledge Distillation](https://arxiv.org/abs/2312.16823) | arXiv |
| Kodge et al. | [Deep Unlearning: Fast and Efficient Training-free Approach to Controlled Forgetting](https://arxiv.org/abs/2312.00761) | arXiv |
| Koh et al. | [Disposable Transfer Learning for Selective Source Task Unlearning](https://arxiv.org/abs/2308.09971) | arXiv |
| Krishna et al. | [Towards Bridging the Gaps between the Right to Explanation and the Right to be Forgotten](https://arxiv.org/abs/2302.04288) | arXiv |
| LeBlond et al. | [Probing the Transition to Dataset-Level Privacy in ML Models Using an Output-Specific and Data-Resolved Privacy Profile](https://arxiv.org/abs/2306.15790) | arXiv |
| Li and Ghosh | [Random Relabeling for Efficient Machine Unlearning](https://arxiv.org/abs/2305.12320) | arXiv |
| Li et al. | [Subspace based Federated Unlearning](https://arxiv.org/abs/2302.12448) | arXiv |
| Li et al. | [Selective and Collaborative Influence Function for Efficient Recommendation Unlearning](https://arxiv.org/abs/2304.10199) | arXiv |
| Li et al. | [Make Text Unlearnable: Exploiting Effective Patterns to Protect Personal Data](https://arxiv.org/abs/2307.00456) | arXiv |
| Li et al. | [Federated Unlearning via Active Forgetting](https://arxiv.org/abs/2307.03363) | arXiv |
| Liu et al. | [Tangent Transformers for Composition, Privacy and Removal](https://arxiv.org/abs/2307.08122) | arXiv |
| Liu et al. | [Recommendation Unlearning via Matrix Correction](https://arxiv.org/abs/2307.15960) | arXiv |
| Liu et al. | [Implicit Concept Removal of Diffusion Models](https://arxiv.org/abs/2310.05873) | arXiv |
| Liu et al. | [Breaking the Trilemma of Privacy, Utility, Efficiency via Controllable Machine Unlearning](https://arxiv.org/abs/2310.18574) | arXiv |
| Liu et al. | [A Survey on Federated Unlearning: Challenges, Methods, and Future Directions](https://arxiv.org/abs/2310.20448) | arXiv |
| Lyu et al. | [One-Dimensional Adapter to Rule Them All: Concepts, Diffusion Models and Erasing Applications](https://arxiv.org/abs/2312.16145) | arXiv |
| Moon et al. | [Feature Unlearning for Generative Models via Implicit Feedback](https://arxiv.org/abs/2303.05699) | arXiv |
| Panda and AP | [FAST: Feature Aware Similarity Thresholding for Weak Unlearning in Black-Box Generative Models](https://arxiv.org/abs/2312.14895) | arXiv |
| Pawelczyk et al. | [In-Context Unlearning: Language Models As Few Shot Unlearners](https://arxiv.org/abs/2310.07579) | arXiv |
| Poppi et al. | [Multi-Class Explainable Unlearning for Image Classification via Weight Filtering](https://arxiv.org/abs/2304.02049) | arXiv |
| Qu et al. | [Learn to Unlearn: A Survey on Machine Unlearning](https://arxiv.org/abs/2305.07512) | arXiv |
| Ramachandra and Sethi | [Machine Unlearning for Causal Inference](https://arxiv.org/abs/2308.13559) | arXiv |
| Shah et al. | [Unlearning via Sparse Representations](https://arxiv.org/abs/2304.04934) | arXiv |
| Shaik et al. | [Exploring the Landscape of Machine Unlearning: A Comprehensive Survey and Taxonomy](https://arxiv.org/abs/2305.06360) | arXiv |
| Shaik et al. | [FRAMU: Attention-based Machine Unlearning using Federated Reinforcement Learning](https://arxiv.org/abs/2309.10283) | arXiv |
| Shi et al. | [DeepClean: Machine Unlearning on the Cheap by Resetting Privacy Sensitive Weights using the Fisher Diagonal](https://arxiv.org/abs/2311.10448) | arXiv |
| Shi et al. | [Detecting Pretraining Data from Large Language Models](https://arxiv.org/abs/2310.16789) | arXiv |
| Si et al. | [Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges](https://arxiv.org/abs/2311.15766) | arXiv |
| Sinha et al. | [Distill to Delete: Unlearning in Graph Networks with Knowledge Distillation](https://arxiv.org/abs/2309.16173) | arXiv |
| Sun et al. | [Generative Adversarial Networks Unlearning](https://arxiv.org/abs/2308.09881) | arXiv |
| Tan et al. | [Unfolded Self-Reconstruction LSH: Towards Machine Unlearning in Approximate Nearest Neighbour Search](https://arxiv.org/abs/2304.02350) | arXiv |
| Tian et al. | [DeRDaVa: Deletion-Robust Data Valuation for Machine Learning](https://arxiv.org/abs/2312.11413) | arXiv |
| Tiwary et al. | [Adapt then Unlearn: Exploiting Parameter Space Semantics for Unlearning in Generative Adversarial Networks](https://arxiv.org/abs/2309.14054) | arXiv |
| Wu et al. | [DEPN: Detecting and Editing Privacy Neurons in Pretrained Language Models](https://arxiv.org/abs/2310.20138) | arXiv |
| Xin et al. | [On the Effectiveness of Unlearning in Session-Based Recommendation](https://arxiv.org/abs/2312.14447) | arXiv |
| Xu et al. | [Netflix and Forget: Efficient and Exact Machine Unlearning from Bi-linear Recommendations](https://arxiv.org/abs/2302.06676) | arXiv |
| Xu and Teng | [Task-Aware Machine Unlearning and Its Application in Load Forecasting](https://arxiv.org/abs/2308.14412) | arXiv |
| Yamashita et al. | [One-Shot Machine Unlearning with Mnemonic Code](https://arxiv.org/abs/2306.05670) | arXiv |
| Yao et al. | [Large Language Model Unlearning](https://arxiv.org/abs/2310.10683) | arXiv |
| Ye et al. | [Reinforcement Unlearning](https://arxiv.org/abs/2312.15910) | arXiv |
| Zha et al. | [To Be Forgotten or To Be Fair: Unveiling Fairness Implications of Machine Unlearning Methods](https://arxiv.org/abs/2302.03350) | arXiv |
| Zhang et al. | [Recommendation Unlearning via Influence Function](https://arxiv.org/abs/2307.02147) | arXiv |
| Zhang et al. | [Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions](https://arxiv.org/abs/2307.03941) | arXiv |
| Zhang et al. | [SecureCut: Federated Gradient Boosting Decision Trees with Efficient Machine Unlearning](https://arxiv.org/abs/2311.13174) | arXiv |
| Zhou et al. | [Audit to Forget: A Unified Method to Revoke Patients' Private Data in Intelligent Healthcare](https://www.biorxiv.org/content/10.1101/2023.02.17.529040v1.abstract) | bioRxiv |
| Jahanian et al. | [Protecting the Neural Networks against FGSM Attack Using Machine Unlearning](https://www.researchsquare.com/article/rs-3239986/v1) | Research Square |
| Fan | [Machine learning and unlearning for IoT anomaly detection](http://dspace.library.uvic.ca/handle/1828/14962) | |
| Su and Li | [Asynchronous Federated Unlearning](https://iqua.ece.toronto.edu/papers/ningxinsu-infocom23.pdf) | |
| Xiong et al. | [Exact-Fun: An Exact and Efficient Federated Unlearning Approach](https://zuobinxiong.github.io/assets/pdf/ExactFedUnlearning.pdf) | |

### 2022
| Author(s) | Title | Venue |
|:--------- | ----- | ----- |
| Marchant et al. | [Hard to Forget: Poisoning Attacks on Certified Machine Unlearning](https://arxiv.org/abs/2109.08266) | AAAI |
| Wu et al. | [PUMA: Performance Unchanged Model Augmentation for Training Data Removal](https://www.aaai.org/AAAI22Papers/AAAI-10608.WuG.pdf) | AAAI |
| Dai et al. | [Knowledge Neurons in Pretrained Transformers](https://arxiv.org/abs/2104.08696) | ACL |
| Chen et al. | [Near-Optimal Task Selection for Meta-Learning with Mutual Information and Online Variational Bayesian Unlearning](https://proceedings.mlr.press/v151/chen22h.html) | AISTATS |
| Nguyen et al. | [Markov Chain Monte Carlo-Based Machine Unlearning: Unlearning What Needs to be Forgotten](https://arxiv.org/abs/2202.13585) | ASIA CCS |
| Qian et al. | [Patient Similarity Learning with Selective Forgetting](https://www.computer.org/csdl/proceedings-article/bibm/2022/09995016/1JC3byZ284E) | BIBM |
| Chen et al. | [Graph Unlearning](https://arxiv.org/abs/2103.14991) | CCS |
| Liu et al. | [Continual Learning and Private Unlearning](https://arxiv.org/abs/2203.12817) | CoLLAs |
| Mehta et al. | [Deep Unlearning via Randomized Conditionally Independent Hessians](https://openaccess.thecvf.com/content/CVPR2022/html/Mehta_Deep_Unlearning_via_Randomized_Conditionally_Independent_Hessians_CVPR_2022_paper.html) | CVPR |
| Cao et al. | [Machine Unlearning Method Based On Projection Residual](https://web10.arxiv.org/abs/2209.15276) | DSAA |
| Ye et al. | [Learning with Recoverable Forgetting](https://arxiv.org/abs/2207.08224) | ECCV |
| Thudi et al. | [Unrolling SGD: Understanding Factors Influencing Machine Unlearning](https://ieeexplore.ieee.org/abstract/document/9797378) | EuroS&P |
| Becker and Liebig | [Certified Data Removal in Sum-Product Networks](https://arxiv.org/abs/2210.01451) | ICKG |
|Fu et al. | [Knowledge Removal in Sampling-based Bayesian Inference](https://openreview.net/forum?id=dTqOcTUOQO) | ICLR |
|Bevan and Atapour-Abarghouei | [Skin Deep Unlearning: Artefact and Instrument Debiasing in the Context of Melanoma Classification](https://arxiv.org/abs/2109.09818) | ICML |
| Hu et al. | [Membership Inference via Backdooring](https://arxiv.org/abs/2206.04823) | IJCAI |
| Yan et al. | [ARCANE: An Efficient Architecture for Exact Machine Unlearning](https://www.ijcai.org/proceedings/2022/0556.pdf) | IJCAI |
| Liu et al. | [The Right to be Forgotten in Federated Learning: An Efficient Realization with Rapid Retraining](https://arxiv.org/abs/2203.07320) | INFOCOM |
| Liu et al. | [Backdoor Defense with Machine Unlearning](https://arxiv.org/abs/2201.09538) | INFOCOM |
| Jiang et al. | [Machine Unlearning Survey](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12500/125006J/Machine-unlearning-survey/10.1117/12.2660330.short?SSO=1) | MCTE |
| Zhang et al. | [Machine Unlearning for Image Retrieval: A Generative Scrubbing Approach](https://dl.acm.org/doi/abs/10.1145/3503161.3548378) | MM |
| Tanno et al. | [Repairing Neural Networks by Leaving the Right Past Behind](https://openreview.net/forum?id=XiwkvDTU10Y) | NeurIPS |
| Zhang et al. | [Prompt Certified Machine Unlearning with Randomized Gradient Smoothing and Quantization](https://openreview.net/pdf?id=ue4gP8ZKiWb) | NeurIPS  |
| Gao et al. | [Deletion Inference, Reconstruction, and Compliance in Machine (Un)Learning](https://arxiv.org/abs/2202.03460) | PETS |
| Sommer et al. | [Athena: Probabilistic Verification of Machine Unlearning](https://web.archive.org/web/20220721061150id_/https://petsymposium.org/popets/2022/popets-2022-0072.pdf) | PoPETs |
| Lu et al. | [FP2-MIA: A Membership Inference Attack Free of Posterior Probability in Machine Unlearning](https://link.springer.com/chapter/10.1007/978-3-031-20917-8_12) | ProvSec |
| Cao et al. | [FedRecover: Recovering from Poisoning Attacks in Federated Learning using Historical Information](https://arxiv.org/abs/2210.10936) | S&P |
| Ganhor et al. | [Unlearning Protected User Attributes in Recommendations with Adversarial Training](https://arxiv.org/abs/2206.04500) | SIGIR |
|Chen et al. | [Recommendation Unlearning](https://dl.acm.org/doi/abs/10.1145/3485447.3511997) | TheWebConf |
| Zhou et al. | [Dynamically Selected Mixup Machine Unlearning](https://ieeexplore.ieee.org/abstract/document/10063433?casa_token=lNgPOVAtM2kAAAAA:O8cLDZYW-e5OBMizqgfA_3sVV6Pc99Rm2QIr5RzzxHLhHC8CZFNZLRZocTI8VTow5rlAaj7nHw) | TrustCom |
| Thudi et al. | [On the Necessity of Auditable Algorithmic Definitions for Machine Unlearning](https://arxiv.org/abs/2110.11891) | USENIX Security |
| Wang et al. | [Federated Unlearning via Class-Discriminative Pruning](https://arxiv.org/abs/2110.11794) | WWW |
| | |
| Fan et al. | [Fast Model Update for IoT Traffic Anomaly Detection with Machine Unlearning](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9927728) | IEEE IoT-J |
| Wu et al. | [Federated Unlearning: Guarantee the Right of Clients to Forget](https://ieeexplore.ieee.org/abstract/document/9964015?casa_token=JSQaZIXrgpcAAAAA:2p-dT8nMx8w5N5yxHOSHqEn6J4_-Xo1yqtqkRf9goxOxe-8k5i0s-_xB0Rns6Gl6SMWGfSYsWg) | IEEE Network |
| Ma et al. | [Learn to Forget: Machine Unlearning Via Neuron Masking](https://ieeexplore.ieee.org/abstract/document/9844865) | IEEE Trans. Dep. Secure Comp. |
| Lu et al. | [Label-only membership inference attacks on machine unlearning without dependence of posteriors](https://onlinelibrary.wiley.com/doi/abs/10.1002/int.23000) | Int. J. Intel. Systems |
| Meng et al. | [Active forgetting via influence estimation for neural networks](https://onlinelibrary.wiley.com/doi/abs/10.1002/int.22981) | Int. J. Intel. Systems |
| Baumhauer et al. | [Machine Unlearning: Linear Filtration for Logit-based Classifiers](https://link.springer.com/article/10.1007/s10994-022-06178-9) | Machine Learning |
| Mahadaven and Mathiodakis | [Certifiable Unlearning Pipelines for Logistic Regression: An Experimental Study](https://www.mdpi.com/2504-4990/4/3/28) | Machine Learning and Knowledge Extraction |
| | |
| Kong et al. | [Forgeability and Membership Inference Attacks](https://dl.acm.org/doi/abs/10.1145/3560830.3563731) | AISec Workshop |
| Kim and Woo | [Efficient Two-Stage Model Retraining for Machine Unlearning](https://openaccess.thecvf.com/content/CVPR2022W/HCIS/html/Kim_Efficient_Two-Stage_Model_Retraining_for_Machine_Unlearning_CVPRW_2022_paper.html) | CVPR Workshop |
| Gong et al. | [Forget-SVGD: Particle-Based Bayesian Federated Unlearning](https://ieeexplore.ieee.org/abstract/document/9820602) | DSL Workshop |
| Chien et al. | [Certified Graph Unlearning](https://arxiv.org/abs/2206.09140) | GLFrontiers Workshop |
| Raunak and Menezes | [Rank-One Editing of Encoder-Decoder Models](https://arxiv.org/abs/2211.13317) | InterNLP Workshop |
| Lycklama et al. | [Cryptographic Auditing for Collaborative Learning](https://pps-lab.com/papers/camel_mlsafety.pdf) | ML Safety Workshop |
| Yoon et al. | [Few-Shot Unlearning](https://download.huan-zhang.com/events/srml2022/accepted/yoon22fewshot.pdf) | SRML Workshop |
| Kong and Chaudhuri | [Data Redaction from Pre-trained GANs](https://openreview.net/forum?id=V7TaczasnAk) | TSRML Workshop |
| Halimi et al. | [Federated Unlearning: How to Efficiently Erase a Client in FL?](https://arxiv.org/abs/2207.05521) | UpML Workshop |
| Rawat et al. | [Challenges and Pitfalls of Bayesian Unlearning](https://arxiv.org/abs/2207.03227) | UpML Workshop |
| | |
| Becker and Liebig | [Evaluating Machine Unlearning via Epistemic Uncertainty](https://arxiv.org/abs/2208.10836) | arXiv |
| Carlini et al. | [The Privacy Onion Effect: Memorization is Relative](https://arxiv.org/abs/2206.10469) | arXiv |
| Chilkuri et al. | [Debugging using Orthogonal Gradient Descent](https://arxiv.org/abs/2206.08489) | arXiv |
| Chourasia et al. | [Forget Unlearning: Towards True Data-Deletion in Machine Learning](https://arxiv.org/abs/2210.08911) | arXiv |
| Chundawat et al. | [Can Bad Teaching Induce Forgetting? Unlearning in Deep Networks using an Incompetent Teacher](https://arxiv.org/abs/2205.08096) | AAAI |
| Cohen et al. | [Control, Confidentiality, and the Right to be Forgotten](https://arxiv.org/abs/2210.07876) | arXiv |
| Eisenhofer et al. | [Verifiable and Provably Secure Machine Unlearning](https://arxiv.org/abs/2210.09126) | arXiv |
| Fraboni et al. | [Sequential Informed Federated Unlearning: Efficient and Provable Client Unlearning in Federated Optimization](https://arxiv.org/abs/2211.11656) | arXiv |
| Gao et al. | [VeriFi: Towards Verifiable Federated Unlearning](https://arxiv.org/abs/2205.12709) | arXiv |
| Goel et al. | [Evaluating Inexact Unlearning Requires Revisiting Forgetting](https://arxiv.org/abs/2201.06640) | arXiv |
| Guo et al. | [Vertical Machine Unlearning: Selectively Removing Sensitive Information From Latent Feature Space](https://arxiv.org/abs/2202.13295) | arXiv |
| Guo et al. | [Efficient Attribute Unlearning: Towards Selective Removal of Input Attributes from Feature Representations](https://arxiv.org/abs/2202.13295) | arXiv |
| Jang et al. | [Knowledge Unlearning for Mitigating Privacy Risks in Language Models](https://arxiv.org/abs/2210.01504) | arXiv |
| Kumar et al. | [Privacy Adhering Machine Un-learning in NLP](https://arxiv.org/abs/2212.09573) | arXiv |
| Liu et al. | [Forgetting Fast in Recommender Systems](https://arxiv.org/abs/2208.06875) | arXiv |
| Liu et al. | [Pre-trained Encoders in Self-Supervised Learning Improve Secure and Privacy-preserving Supervised Learning](https://arxiv.org/abs/2212.03334) | arXiv |
| Lu et al. | [Quark: Controllable Text Generation with Reinforced Unlearning](https://arxiv.org/abs/2205.13636) | arXiv |
| Malnick et al. | [Taming a Generative Model](https://arxiv.org/abs/2211.16488) | arXiv |
| Mercuri et al. | [An Introduction to Machine Unlearning](https://arxiv.org/abs/2209.00939) | arXiv |
| Mireshghallah et al. | [Non-Parametric Temporal Adaptation for Social Media Topic Classification](https://arxiv.org/abs/2209.05706) | arXiv |
| Nguyen et al. | [A Survey of Machine Unlearning](https://arxiv.org/abs/2209.02299) | arXiv |
| Pan et al. | [Unlearning Nonlinear Graph Classifiers in the Limited Training Data Regime](https://arxiv.org/abs/2211.03216) | arXiv |
| Pan et al. | [Machine Unlearning of Federated Clusters](https://arxiv.org/abs/2210.16424) | arXiv |
| Said et al. | [A Survey of Graph Unlearning](https://arxiv.org/abs/2310.02164) | arXiv |
| Tarun et al. | [Deep Regression Unlearning](https://arxiv.org/abs/2210.08196) | ICML |
| Weng et al. | [Proof of Unlearning: Definitions and Instantiation](https://arxiv.org/abs/2210.11334) | arXiv |
| Wu et al. | [Federated Unlearning with Knowledge Distillation](https://arxiv.org/abs/2201.09441) | arXiv |
| Yu et al. | [LegoNet: A Fast and Exact Unlearning Architecture](https://arxiv.org/abs/2210.16023) | arXiv |
| Yoon et al. | [Few-Shot Unlearning by Model Inversion](https://arxiv.org/abs/2205.15567) | arXiv |
| Yuan et al. | [Federated Unlearning for On-Device Recommendation](https://arxiv.org/abs/2210.10958) | arXiv |
| Zhu et al. | [Selective Amnesia: On Efficient, High-Fidelity and Blind Suppression of Backdoor Effects in Trojaned Machine Learning Models](https://arxiv.org/abs/2212.04687) | arXiv |
| Cong and Mahdavi | [Privacy Matters! Efficient Graph Representation Unlearning with Data Removal Guarantee](https://congweilin.github.io/CongWeilin.io/files/Projector.pdf) | |
| Cong and Mahdavi | [GraphEditor: An Efficient Graph Representation Learning and Unlearning Approach](https://congweilin.github.io/CongWeilin.io/files/GraphEditor.pdf) | |
| Wu et al. | [Provenance-based Model Maintenance: Implications for Privacy](http://sites.computer.org/debull/A22mar/p37.pdf) |

### 2021

| Author(s) | Title | Venue |
|:--------- | ----- | ----- |
| Graves et al. | [Amnesiac Machine Learning](https://ojs.aaai.org/index.php/AAAI/article/view/17371) | AAAI |
| Yu et al. | [Membership Inference with Privately Augmented Data Endorses the Benign while Suppresses the Adversary](https://arxiv.org/abs/2007.10567) | AAAI |
| Izzo et al. | [Approximate Data Deletion from Machine Learning Models: Algorithms and Evaluations](https://arxiv.org/abs/2002.10077) | AISTATS |
| Li et al. | [Online Forgetting Process for Linear Regression Models](https://arxiv.org/abs/2012.01668) | AISTATS |
| Neel et al. | [Descent-to-Delete: Gradient-Based Methods for Machine Unlearning](http://proceedings.mlr.press/v132/neel21a.html) | ALT |
| Chen et al. | [REFIT: A Unified Watermark Removal Framework For Deep Learning Systems With Limited Data](https://dl.acm.org/doi/abs/10.1145/3433210.3453079) | ASIA CCS |
| Chen et al. | [When Machine Unlearning Jeopardizes Privacy](https://arxiv.org/abs/2005.02205) | CCS |
| Ullah et al. | [Machine Unlearning via Algorithmic Stability](http://proceedings.mlr.press/v134/ullah21a.html) | COLT |
| Golatkar et al. | [Mixed-Privacy Forgetting in Deep Networks](https://arxiv.org/abs/2012.13431) | CVPR |
| Dang et al. | [Right to Be Forgotten in the Age of Machine Learning](https://link.springer.com/chapter/10.1007/978-3-030-71782-7_35) | ICADS |
| Brophy and Lowd | [Machine Unlearning for Random Forests](http://proceedings.mlr.press/v139/brophy21a.html) | ICML |
| Huang et al. | [Unlearnable Examples: Making Personal Data Unexploitable](https://arxiv.org/abs/2101.04898) | ICLR |
| Goyal et al. | [Revisiting Machine Learning Training Process for Enhanced Data Privacy](https://dl.acm.org/doi/10.1145/3474124.3474208) | IC3 |
| Tahiliani et al. | [Machine Unlearning: Its Need and Implementation Strategies](https://dl.acm.org/doi/abs/10.1145/3474124.3474158) | IC3 |
| Shibata et al. | [Learning with Selective Forgetting](https://www.ijcai.org/proceedings/2021/0137.pdf) | IJCAI |
| Liu et al. | [Federated Unlearning](https://arxiv.org/abs/2012.13891) | IWQoS |
| Huang et al. | [EMA: Auditing Data Removal from Trained Models](https://link.springer.com/chapter/10.1007/978-3-030-87240-3_76) | MICCAI |
| Gupta et al. | [Adaptive Machine Unlearning](https://arxiv.org/abs/2106.04378) | NeurIPS |
| Khan and Swaroop | [Knowledge-Adaptation Priors](https://proceedings.neurips.cc/paper/2021/hash/a4380923dd651c195b1631af7c829187-Abstract.html) | NeurIPS |
| Sekhari et al. | [Remember What You Want to Forget: Algorithms for Machine Unlearning](https://arxiv.org/abs/2103.03279) | NeurIPS |
| Liu et al. | [FedEraser: Enabling Efficient Client-Level Data Removal from Federated Learning Models](https://ieeexplore.ieee.org/abstract/document/9521274) | IWQoS |
| Bourtoule et al. | [Machine Unlearning](https://arxiv.org/abs/1912.03817) | S&P |
| Schelter et al. | [HedgeCut: Maintaining Randomised Trees for Low-Latency Machine Unlearning](https://ssc.io/pdf/rdm235.pdf) | SIGMOD |
| Gong et al. | [Bayesian Variational Federated Learning and Unlearning in Decentralized Networks](https://ieeexplore.ieee.org/abstract/document/9593225) | SPAWC |
| | |
| Aldaghri et al. | [Coded Machine Unlearning](https://ieeexplore.ieee.org/abstract/document/9458237) | IEEE Access |
| Liu et al. | [RevFRF: Enabling Cross-domain Random Forest Training with Revocable Federated Learning](https://ieeexplore.ieee.org/abstract/document/9514457) | IEEE Trans. Dep. Secure Comp. |
| | |
| Wang and Schelter | [Efficiently Maintaining Next Basket Recommendations under Additions and Deletions of Baskets and Items](https://arxiv.org/abs/2201.13313) | ORSUM Workshop |
| Jose and Simeone | [A Unified PAC-Bayesian Framework for Machine Unlearning via Information Risk Minimization](https://ieeexplore.ieee.org/abstract/document/9596170) | MLSP Workshop |
| Peste et al. | [SSSE: Efficiently Erasing Samples from Trained Machine Learning Models](https://arxiv.org/abs/2107.03860) | PRIML Workshop |
| | |
| Chen et al. | [Machine unlearning via GAN](https://arxiv.org/abs/2111.11869) | arXiv |
| He et al. | [DeepObliviate: A Powerful Charm for Erasing Data Residual Memory in Deep Neural Networks](https://arxiv.org/abs/2105.06209) | arXiv |
| Madahaven and Mathioudakis | [Certifiable Machine Unlearning for Linear Models](https://arxiv.org/abs/2106.15093) | arXiv |
| Parne et al. | [Machine Unlearning: Learning, Polluting, and Unlearning for Spam Email](https://arxiv.org/abs/2111.14609) | arXiv |
| Thudi et al. | [Bounding Membership Inference ](https://arxiv.org/abs/2202.12232) | arXiv |
| Zeng et al. | [Learning to Refit for Convex Learning Problems](https://arxiv.org/abs/2111.12545) | arXiv |

### 2020
| Author(s) | Title | Venue |
|:--------- | ----- | ----- |
| Tople te al. | [Analyzing Information Leakage of Updates to Natural Language Models](https://dl.acm.org/doi/abs/10.1145/3372297.3417880) | CCS |
| Golatkar et al. | [Eternal Sunshine of the Spotless Net: Selective Forgetting in Deep Networks](https://arxiv.org/abs/1911.04933) | CVPR |
| Golatkar et al. | [Forgetting Outside the Box: Scrubbing Deep Networks of Information Accessible from Input-Output Observations](https://arxiv.org/abs/1911.04933) | ECCV |
| Garg et al. | [Formalizing Data Deletion in the Context of the Right to be Forgotten](https://arxiv.org/abs/2002.10635) | EUROCRYPT |
| Guo et al. | [Certified Data Removal from Machine Learning Models](https://arxiv.org/abs/1911.03030) | ICML |
| Wu et al. | [DeltaGrad: Rapid Retraining of Machine Learning Models](https://icml.cc/virtual/2020/poster/5915) | ICML |
| Nguyen et al. | [Variational Bayesian Unlearning](https://proceedings.neurips.cc/paper/2020/hash/b8a6550662b363eb34145965d64d0cfb-Abstract.html) | NeurIPS |
| | |
| Liu et al. | [Learn to Forget: User-Level Memorization Elimination in Federated Learning](https://www.researchgate.net/profile/Ximeng-Liu-5/publication/340134612\_Learn\_to\_Forget\_User-Level\_Memorization\_Elimination\_in\_Federated\_Learning/links/5e849e64a6fdcca789e5f955/Learn-to-Forget-User-Level-Memorization-Elimination-in-Federated-Learning.pdf) | researchgate |
| Felps et al. | [Class Clown: Data Redaction in Machine Unlearning at Enterprise Scale](https://arxiv.org/abs/2012.04699) | arXiv |
| Sommer et al. | [Towards Probabilistic Verification of Machine Unlearning](https://arxiv.org/abs/2003.04247) | arXiv |

### 2019
| Author(s) | Title | Venue |
|:--------- | ----- | ----- |
| Shintre et al. | [Making Machine Learning Forget](https://link.springer.com/chapter/10.1007/978-3-030-21752-5_6) | APF |
| Du et al. | [Lifelong Anomaly Detection Through Unlearning](https://dl.acm.org/doi/abs/10.1145/3319535.3363226) | CCS |
| Kim et al. | [Learning Not to Learn: Training Deep Neural Networks With Biased Data](https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Learning_Not_to_Learn_Training_Deep_Neural_Networks_With_Biased_CVPR_2019_paper.html) | CVPR |
| Ginart et al. | [Making AI Forget You: Data Deletion in Machine Learning](http://papers.nips.cc/paper/8611-making-ai-forget-you-data-deletion-in-machine-learning) | NeurIPS |
| Wang et al. | [Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks](https://people.cs.vt.edu/vbimal/publications/backdoor-sp19.pdf) | S&P |
| | |
| Chen et al. | [A Novel Online Incremental and Decremental Learning Algorithm Based on Variable Support Vector Machine](https://link.springer.com/article/10.1007/s10586-018-1772-4) | Cluster Computing |
| | |
| Schelter | [“Amnesia” – Towards Machine Learning Models That Can Forget User Data Very Fast](http://cidrdb.org/cidr2020/papers/p32-schelter-cidr20.pdf) | AIDB Workshop |

### 2018
| Author(s) | Title | Venue |
|:--------- | ----- | ----- |
| Cao et al. | [Efficient Repair of Polluted Machine Learning Systems via Causal Unlearning](https://dl.acm.org/citation.cfm?id=3196517) | ASIACCS |
| | |
| Villaronga et al. | [Humans Forget, Machines Remember: Artificial Intelligence and the Right to Be Forgotten](https://www.sciencedirect.com/science/article/pii/S0267364917302091) | Computer Law & Security Review |
| Veale et al. | [Algorithms that remember: model inversion attacks and data protection law](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2018.0083) | The Royal Society |
| | |
| European Union | [GDPR](https://gdpr.eu/) |
| State of California | [California Consumer Privacy Act](https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180AB375) |

### 2017
| Author(s) | Title | Venue |
|:--------- | ----- | ----- |
| Shokri et al. | [Membership Inference Attacks Against Machine Learning Models](https://ieeexplore.ieee.org/abstract/document/7958568) | S&P |
| Kwak et al. | [Let Machines Unlearn--Machine Unlearning and the Right to be Forgotten](https://aisel.aisnet.org/amcis2017/InformationSystems/Presentations/14/) | SIGSEC |

### Before 2017
| Author(s) | Title | Venue |
|:--------- | ----- | ----- |
| Ganin et al. |  [Domain-Adversarial Training of Neural Networks](https://www.jmlr.org/papers/volume17/15-239/15-239.pdf) | JMLR 2016 |
| Cao and Yang |  [Towards Making Systems Forget with Machine Unlearning](https://ieeexplore.ieee.org/abstract/document/7163042) | S&P 2015 |
| Tsai et al. | [Incremental and decremental training for linear classification](https://dl.acm.org/citation.cfm?id=2623661) | KDD 2014 |
| Karasuyama and Takeuchi | [Multiple Incremental Decremental Learning of Support Vector Machines](https://ieeexplore.ieee.org/abstract/document/5484614) | NeurIPS 2009 |
| Duan et al. | [Decremental Learning Algorithms for Nonlinear Langrangian and Least Squares Support Vector Machines](https://pdfs.semanticscholar.org/312c/677f0882d0dfd60bfd77346588f52aefd10f.pdf) | OSB 2007 |
| Romero et al. | [Incremental and Decremental Learning for Linear Support Vector Machines](https://link.springer.com/chapter/10.1007/978-3-540-74690-4_22) | ICANN 2007 |
| Tveit et al. | [Incremental and Decremental Proximal Support Vector Classification using Decay Coefficients](https://link.springer.com/chapter/10.1007/978-3-540-45228-7_42) | DaWaK 2003 |
| Tveit and Hetland | [Multicategory Incremental Proximal Support Vector Classifiers](https://link.springer.com/chapter/10.1007/978-3-540-45224-9_54) | KES 2003 |
| Cauwenberghs and Poggio | [Incremental and Decremental Support Vector Machine Learning](http://papers.nips.cc/paper/1814-incremental-and-decremental-support-vector-machine-learning.pdf) | NeurIPS 2001 |
| Canada | [PIPEDA](https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/the-personal-information-protection-and-electronic-documents-act-pipeda/) | 2000 |
